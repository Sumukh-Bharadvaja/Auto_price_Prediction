{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import zscore\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor,AdaBoostRegressor\n",
    "\n",
    "from sklearn.linear_model import Ridge, RidgeCV, Lasso,LassoCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score,mean_absolute_error\n",
    "\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# for warnings \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symboling</th>\n",
       "      <th>normalized_losses</th>\n",
       "      <th>make</th>\n",
       "      <th>num_of_doors</th>\n",
       "      <th>body_style</th>\n",
       "      <th>drive_wheels</th>\n",
       "      <th>engine_location</th>\n",
       "      <th>wheel_base</th>\n",
       "      <th>length</th>\n",
       "      <th>width</th>\n",
       "      <th>...</th>\n",
       "      <th>peak_rpm</th>\n",
       "      <th>city_mpg</th>\n",
       "      <th>highway_mpg</th>\n",
       "      <th>price</th>\n",
       "      <th>city_L/100km</th>\n",
       "      <th>horsepower-binned</th>\n",
       "      <th>diesel</th>\n",
       "      <th>gas</th>\n",
       "      <th>aspiration_std</th>\n",
       "      <th>aspiration_turbo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>122.0</td>\n",
       "      <td>alfa-romero</td>\n",
       "      <td>two</td>\n",
       "      <td>convertible</td>\n",
       "      <td>rwd</td>\n",
       "      <td>front</td>\n",
       "      <td>88.6</td>\n",
       "      <td>0.811148</td>\n",
       "      <td>0.890278</td>\n",
       "      <td>...</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>16500</td>\n",
       "      <td>11.190476</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>122.0</td>\n",
       "      <td>alfa-romero</td>\n",
       "      <td>two</td>\n",
       "      <td>hatchback</td>\n",
       "      <td>rwd</td>\n",
       "      <td>front</td>\n",
       "      <td>94.5</td>\n",
       "      <td>0.822681</td>\n",
       "      <td>0.909722</td>\n",
       "      <td>...</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>19</td>\n",
       "      <td>26</td>\n",
       "      <td>16500</td>\n",
       "      <td>12.368421</td>\n",
       "      <td>Medium</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>164.0</td>\n",
       "      <td>audi</td>\n",
       "      <td>four</td>\n",
       "      <td>sedan</td>\n",
       "      <td>fwd</td>\n",
       "      <td>front</td>\n",
       "      <td>99.8</td>\n",
       "      <td>0.848630</td>\n",
       "      <td>0.919444</td>\n",
       "      <td>...</td>\n",
       "      <td>5500.0</td>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "      <td>13950</td>\n",
       "      <td>9.791667</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>164.0</td>\n",
       "      <td>audi</td>\n",
       "      <td>four</td>\n",
       "      <td>sedan</td>\n",
       "      <td>4wd</td>\n",
       "      <td>front</td>\n",
       "      <td>99.4</td>\n",
       "      <td>0.848630</td>\n",
       "      <td>0.922222</td>\n",
       "      <td>...</td>\n",
       "      <td>5500.0</td>\n",
       "      <td>18</td>\n",
       "      <td>22</td>\n",
       "      <td>17450</td>\n",
       "      <td>13.055556</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>161.0</td>\n",
       "      <td>audi</td>\n",
       "      <td>two</td>\n",
       "      <td>sedan</td>\n",
       "      <td>fwd</td>\n",
       "      <td>front</td>\n",
       "      <td>99.8</td>\n",
       "      <td>0.851994</td>\n",
       "      <td>0.920833</td>\n",
       "      <td>...</td>\n",
       "      <td>5500.0</td>\n",
       "      <td>19</td>\n",
       "      <td>25</td>\n",
       "      <td>15250</td>\n",
       "      <td>12.368421</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   symboling  normalized_losses         make num_of_doors   body_style  \\\n",
       "0          3              122.0  alfa-romero          two  convertible   \n",
       "1          1              122.0  alfa-romero          two    hatchback   \n",
       "2          2              164.0         audi         four        sedan   \n",
       "3          2              164.0         audi         four        sedan   \n",
       "4          2              161.0         audi          two        sedan   \n",
       "\n",
       "  drive_wheels engine_location  wheel_base    length     width  ...  peak_rpm  \\\n",
       "0          rwd           front        88.6  0.811148  0.890278  ...    5000.0   \n",
       "1          rwd           front        94.5  0.822681  0.909722  ...    5000.0   \n",
       "2          fwd           front        99.8  0.848630  0.919444  ...    5500.0   \n",
       "3          4wd           front        99.4  0.848630  0.922222  ...    5500.0   \n",
       "4          fwd           front        99.8  0.851994  0.920833  ...    5500.0   \n",
       "\n",
       "   city_mpg highway_mpg  price  city_L/100km horsepower-binned  diesel  gas  \\\n",
       "0        21          27  16500     11.190476               Low       0    1   \n",
       "1        19          26  16500     12.368421            Medium       0    1   \n",
       "2        24          30  13950      9.791667               Low       0    1   \n",
       "3        18          22  17450     13.055556               Low       0    1   \n",
       "4        19          25  15250     12.368421               Low       0    1   \n",
       "\n",
       "   aspiration_std  aspiration_turbo  \n",
       "0               1                 0  \n",
       "1               1                 0  \n",
       "2               1                 0  \n",
       "3               1                 0  \n",
       "4               1                 0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'Processed_data.csv'\n",
    "df = pd.read_csv(path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200 entries, 0 to 199\n",
      "Data columns (total 30 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   symboling          200 non-null    int64  \n",
      " 1   normalized_losses  200 non-null    float64\n",
      " 2   make               200 non-null    object \n",
      " 3   num_of_doors       200 non-null    object \n",
      " 4   body_style         200 non-null    object \n",
      " 5   drive_wheels       200 non-null    object \n",
      " 6   engine_location    200 non-null    object \n",
      " 7   wheel_base         200 non-null    float64\n",
      " 8   length             200 non-null    float64\n",
      " 9   width              200 non-null    float64\n",
      " 10  height             200 non-null    float64\n",
      " 11  curb_weight        200 non-null    int64  \n",
      " 12  engine_type        200 non-null    object \n",
      " 13  num_of_cylinders   200 non-null    object \n",
      " 14  engine_size        200 non-null    int64  \n",
      " 15  fuel_system        200 non-null    object \n",
      " 16  bore               200 non-null    float64\n",
      " 17  stroke             200 non-null    float64\n",
      " 18  compression_ratio  200 non-null    float64\n",
      " 19  horsepower         200 non-null    int64  \n",
      " 20  peak_rpm           200 non-null    float64\n",
      " 21  city_mpg           200 non-null    int64  \n",
      " 22  highway_mpg        200 non-null    int64  \n",
      " 23  price              200 non-null    int64  \n",
      " 24  city_L/100km       200 non-null    float64\n",
      " 25  horsepower-binned  200 non-null    object \n",
      " 26  diesel             200 non-null    int64  \n",
      " 27  gas                200 non-null    int64  \n",
      " 28  aspiration_std     200 non-null    int64  \n",
      " 29  aspiration_turbo   200 non-null    int64  \n",
      "dtypes: float64(10), int64(11), object(9)\n",
      "memory usage: 47.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us create a function to view the mse, rmse,r2 score, p value and t test of the model ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_performance(X_train, X_test, y_train, y_test, model):\n",
    "    try:   \n",
    "        # Fitting the model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predicting on test data\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Calculating the metrics\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "        # For linear models, calculating p-value and t-statistic\n",
    "        if isinstance(model, LinearRegression):\n",
    "            X_train_sm = sm.add_constant(X_train)  # adding a constant\n",
    "            model_sm = sm.OLS(y_train, X_train_sm).fit()\n",
    "            p_values = model_sm.pvalues\n",
    "            t_stats = model_sm.tvalues\n",
    "            return mse, rmse, r2, p_values, t_stats\n",
    "        else:\n",
    "            # For non-linear models like Random Forest, we return None for p-value and t-statistic\n",
    "            return mse, rmse, r2, None, None\n",
    "\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Since we now have a better idea of what our data looks like and which variables are important to take into account when predicting the car price. We have narrowed it down to the following variables:</p>\n",
    "\n",
    "Continuous numerical variables:\n",
    "<ul>\n",
    "    <li>Length</li>\n",
    "    <li>Width</li>\n",
    "    <li>Curb-weight</li>\n",
    "    <li>Engine-size</li>\n",
    "    <li>Horsepower</li>\n",
    "    <li>City-mpg</li>\n",
    "    <li>Highway-mpg</li>\n",
    "    <li>Wheel-base</li>\n",
    "    <li>Bore</li>\n",
    "</ul>\n",
    "    \n",
    "Categorical variables:\n",
    "<ul>\n",
    "    <li>Drive-wheels</li>\n",
    "</ul>\n",
    "\n",
    "<p>As we now move into building machine learning models to automate our analysis, feeding the model with variables that meaningfully affect our target variable will improve our model's prediction performance.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>price</td>      <th>  R-squared:         </th> <td>   0.820</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.811</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   96.01</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 29 Dec 2023</td> <th>  Prob (F-statistic):</th> <td>7.99e-66</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>22:08:27</td>     <th>  Log-Likelihood:    </th> <td> -1908.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   200</td>      <th>  AIC:               </th> <td>   3837.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   190</td>      <th>  BIC:               </th> <td>   3870.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     9</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>       <td>-4.936e+04</td> <td> 1.49e+04</td> <td>   -3.303</td> <td> 0.001</td> <td>-7.88e+04</td> <td>-1.99e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>length</th>      <td>-1.495e+04</td> <td> 1.24e+04</td> <td>   -1.202</td> <td> 0.231</td> <td>-3.95e+04</td> <td> 9579.645</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>width</th>       <td> 4.558e+04</td> <td> 1.93e+04</td> <td>    2.360</td> <td> 0.019</td> <td> 7477.277</td> <td> 8.37e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>highway_mpg</th> <td>  187.4874</td> <td>  177.179</td> <td>    1.058</td> <td> 0.291</td> <td> -162.003</td> <td>  536.978</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>curb_weight</th> <td>    3.0677</td> <td>    1.671</td> <td>    1.836</td> <td> 0.068</td> <td>   -0.229</td> <td>    6.364</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>engine_size</th> <td>   79.1953</td> <td>   14.265</td> <td>    5.552</td> <td> 0.000</td> <td>   51.057</td> <td>  107.334</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower</th>  <td>   60.8113</td> <td>   17.576</td> <td>    3.460</td> <td> 0.001</td> <td>   26.142</td> <td>   95.481</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>city_mpg</th>    <td> -170.0137</td> <td>  189.254</td> <td>   -0.898</td> <td> 0.370</td> <td> -543.322</td> <td>  203.294</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>wheel_base</th>  <td>  122.2154</td> <td>  105.691</td> <td>    1.156</td> <td> 0.249</td> <td>  -86.263</td> <td>  330.694</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bore</th>        <td>-1310.8187</td> <td> 1236.176</td> <td>   -1.060</td> <td> 0.290</td> <td>-3749.211</td> <td> 1127.573</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>27.432</td> <th>  Durbin-Watson:     </th> <td>   0.783</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  61.328</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.623</td> <th>  Prob(JB):          </th> <td>4.82e-14</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.410</td> <th>  Cond. No.          </th> <td>2.51e+05</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 2.51e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  price   R-squared:                       0.820\n",
       "Model:                            OLS   Adj. R-squared:                  0.811\n",
       "Method:                 Least Squares   F-statistic:                     96.01\n",
       "Date:                Fri, 29 Dec 2023   Prob (F-statistic):           7.99e-66\n",
       "Time:                        22:08:27   Log-Likelihood:                -1908.6\n",
       "No. Observations:                 200   AIC:                             3837.\n",
       "Df Residuals:                     190   BIC:                             3870.\n",
       "Df Model:                           9                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===============================================================================\n",
       "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------\n",
       "const       -4.936e+04   1.49e+04     -3.303      0.001   -7.88e+04   -1.99e+04\n",
       "length      -1.495e+04   1.24e+04     -1.202      0.231   -3.95e+04    9579.645\n",
       "width        4.558e+04   1.93e+04      2.360      0.019    7477.277    8.37e+04\n",
       "highway_mpg   187.4874    177.179      1.058      0.291    -162.003     536.978\n",
       "curb_weight     3.0677      1.671      1.836      0.068      -0.229       6.364\n",
       "engine_size    79.1953     14.265      5.552      0.000      51.057     107.334\n",
       "horsepower     60.8113     17.576      3.460      0.001      26.142      95.481\n",
       "city_mpg     -170.0137    189.254     -0.898      0.370    -543.322     203.294\n",
       "wheel_base    122.2154    105.691      1.156      0.249     -86.263     330.694\n",
       "bore        -1310.8187   1236.176     -1.060      0.290   -3749.211    1127.573\n",
       "==============================================================================\n",
       "Omnibus:                       27.432   Durbin-Watson:                   0.783\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               61.328\n",
       "Skew:                           0.623   Prob(JB):                     4.82e-14\n",
       "Kurtosis:                       5.410   Cond. No.                     2.51e+05\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 2.51e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=df[['length','width','highway_mpg','curb_weight','engine_size','horsepower','city_mpg','wheel_base','bore']]\n",
    "y=df['price']\n",
    "\n",
    "x1 = sm.add_constant(x)\n",
    "result=sm.OLS(y,x1).fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>The model diagnostics show:</h4>\n",
    "\n",
    "* The Durbin-Watson statistic is 0.783, suggesting that there may be some autocorrelation in the residuals of the model.\n",
    "* The Jarque-Bera test has a statistic of 61.3238 with a p-value of 0.000, indicating that the residuals may not be normally distributed (since the p-value is less than 0.05).\n",
    "* The condition number is high (2.51e+05), suggesting potential multicollinearity or other numerical problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Feature Engineering using Decision Tree Regressor</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final= df[['length','width','highway_mpg','curb_weight','engine_size','horsepower','city_mpg','wheel_base','bore','price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_z = df_final.apply(zscore)\n",
    "df_z=pd.DataFrame(df_z,columns=df_z.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, all the attributes in the same scale(unit) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeRegressor()"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=df_z[['length','width','highway_mpg','curb_weight','engine_size','horsepower','city_mpg','wheel_base','bore']]\n",
    "y=df_z['price']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state = 1,shuffle=True)\n",
    "\n",
    "dt_model = DecisionTreeRegressor()\n",
    "dt_model.fit(X_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importances: \n",
      "                   Imp\n",
      "length       0.008370\n",
      "width        0.003870\n",
      "highway_mpg  0.011972\n",
      "curb_weight  0.251480\n",
      "engine_size  0.649063\n",
      "horsepower   0.034433\n",
      "city_mpg     0.009323\n",
      "wheel_base   0.009382\n",
      "bore         0.022107\n"
     ]
    }
   ],
   "source": [
    "print('Feature importances: \\n',pd.DataFrame(dt_model.feature_importances_,columns=['Imp'],index=X_train.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the decision tree regressor, we found out the most important features which can explain the price of the automobile are\n",
    " - Engine Size\n",
    " - Curb weight\n",
    " - Horsepower\n",
    " - highway-mpg\n",
    "\n",
    "This confirms the EDA results and reduces the number of important features as well\n",
    "\n",
    "Further analysis needs to be done for the followin features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.07954117900179904, 0.28203045757825346, 0.9314125688036166, None, None)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_dt= model_performance(X_train, X_test, y_train, y_test,dt_model)\n",
    "metrics_dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error rate for test data set is as shown above.\n",
    "- The R2 score explains around 93.32% of variance in the data with rmse of 0.2782\n",
    "- The model might be overfitting  which can be checked by comparing the values of train data with the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check the reliability of the model we will use train test r2 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score on Training data using Decision tree: 0.9997480847763237\n",
      "R2 Score on Test data using Decision Tree: 0.9314125688036166\n"
     ]
    }
   ],
   "source": [
    "r2_train_dt=dt_model.score(X_train,y_train)\n",
    "r2_test_dt=metrics_dt[2]\n",
    "print('R2 score on Training data using Decision tree:',r2_train_dt)\n",
    "print('R2 Score on Test data using Decision Tree:',r2_test_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore the model must be overfitting due to variablity in data since it is predicting around 99% accurately in train data and accuray drops to 93%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the feature importance of the decision tree model we can further analyse dynamics using other Ensemble Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Decision Tree Regressor - Features</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeRegressor()"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dt_1=DecisionTreeRegressor()\n",
    "\n",
    "data_dt=df_z.copy()\n",
    "\n",
    "X_final= X. drop(['length','width','bore','city_mpg','wheel_base'],axis=1)\n",
    "y=df['price']\n",
    "\n",
    "X_train_dt,X_test_dt,y_train_dt,y_test_dt= train_test_split(X_final,y, test_size = 0.3, random_state = 1,shuffle=True)\n",
    "\n",
    "model_dt_1.fit(X_train_dt , y_train_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_dt_final=model_performance(X_train_dt,X_test_dt,y_train_dt,y_test_dt,model_dt_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6283675.3875, 2506.72602960515, 0.914206291400252, None, None)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_dt_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score on Training data using Decision tree: 0.9997310635934072\n",
      "R2 Score on Test data using Decision Tree: 0.914206291400252\n"
     ]
    }
   ],
   "source": [
    "r2_train_dt_final=model_dt_1.score(X_train_dt,y_train_dt)\n",
    "r2_test_dt_final=metrics_dt_final[2]\n",
    "print('R2 score on Training data using Decision tree:',r2_train_dt_final)\n",
    "print('R2 Score on Test data using Decision Tree:',r2_test_dt_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model here as well is overfitting , Lets now cnduct k-fold Cross validation for the decision tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy:  0.7679072290725739\n",
      "Standard Deviation:  0.24297637487573437\n"
     ]
    }
   ],
   "source": [
    "num_folds = 18\n",
    "seed = 77\n",
    "kfold = KFold(n_splits=num_folds, random_state=seed,shuffle=True)\n",
    "results1 = cross_val_score(model_dt_1,X_final, y, cv=kfold)\n",
    "accuracy=np.mean(abs(results1))\n",
    "print('Average accuracy: ',accuracy)\n",
    "print('Standard Deviation: ',results1.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of k-folds decision tree for the feature selected decreased from 91 to 76 the model cannot be used on the new dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Random Forest Regressor </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf= RandomForestRegressor()\n",
    "\n",
    "X_final= X. drop(['length','width','bore','city_mpg','wheel_base'],axis=1)\n",
    "y=df['price']\n",
    "\n",
    "X_train_dt,X_test_dt,y_train_dt,y_test_dt= train_test_split(X_final,y, test_size = 0.3, random_state = 1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor()"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rf.fit(X_train_dt,y_train_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5883931.381176794, 2425.681632279223, 0.919664167353108, None, None)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_rf=model_performance(X_train_dt,X_test_dt,y_train_dt,y_test_dt,model_rf)\n",
    "metrics_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score on Training data using Random Forest: 0.9847558590759481\n",
      "R2 Score on Test data using Random Forest: 0.919664167353108\n"
     ]
    }
   ],
   "source": [
    "r2_train_rf=model_rf.score(X_train_dt,y_train_dt)\n",
    "r2_test_rf=metrics_rf[2]\n",
    "print('R2 score on Training data using Random Forest:',r2_train_rf)\n",
    "print('R2 Score on Test data using Random Forest:',r2_test_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model seems to be slightly overfitting as accuracy of train data is more than test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Random Forest Regressor K-fold cross validation  </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy:  0.8604558081126926\n",
      "Standard Deviation:  0.11049934243081878\n"
     ]
    }
   ],
   "source": [
    "num_folds = 18\n",
    "seed = 77\n",
    "kfold = KFold(n_splits=num_folds, random_state=seed,shuffle=True)\n",
    "results2 = cross_val_score(model_rf,X_final, y, cv=kfold)\n",
    "accuracy_rf=np.mean(abs(results2))\n",
    "print('Average accuracy: ',accuracy_rf)\n",
    "print('Standard Deviation: ',results2.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is overfitting since the accuracy of k fold cross validation is reduced to 0.86 from 0.93, the SD is around 0.1 suggesting that here is 10% variance in each fold of test validation test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Gradient Boosting Regressor   </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gbr= GradientBoostingRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {color: black;background-color: white;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" checked><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingRegressor()"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gbr.fit(X_train_dt,y_train_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5267418.786353528, 2295.0857906303913, 0.9280816775913932, None, None)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_gbr=model_performance(X_train_dt,X_test_dt,y_train_dt,y_test_dt,model_gbr)\n",
    "metrics_gbr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score on Training data using Gradient Boosting Regressor: 0.9906822159809477\n",
      "R2 Score on Test data using Gradient Boosting Regressor: 0.9280816775913932\n"
     ]
    }
   ],
   "source": [
    "r2_train_gbr=model_gbr.score(X_train_dt,y_train_dt)\n",
    "r2_test_gbr=metrics_gbr[2]\n",
    "print('R2 score on Training data using Gradient Boosting Regressor:',r2_train_gbr)\n",
    "print('R2 Score on Test data using Gradient Boosting Regressor:',r2_test_gbr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is slightly overfitted compared to previous model this is giving better accuracy , let us continue with k-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy:  0.9208711343790963\n",
      "Standard Deviation:  0.042131833078836924\n"
     ]
    }
   ],
   "source": [
    "num_folds = 16\n",
    "seed = 83\n",
    "kfold = KFold(n_splits=num_folds, random_state=seed,shuffle=True)\n",
    "results3 = cross_val_score(model_gbr,X_final, y, cv=kfold)\n",
    "accuracy3=np.mean(abs(results3))\n",
    "print('Average accuracy: ',accuracy3)\n",
    "print('Standard Deviation: ',results3.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is valid since the Cross validation and test data are providing the same results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Ada Boosting Regressor   </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-11 {color: black;background-color: white;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>AdaBoostRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" checked><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostRegressor</label><div class=\"sk-toggleable__content\"><pre>AdaBoostRegressor()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "AdaBoostRegressor()"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_abr=AdaBoostRegressor()\n",
    "model_abr.fit(X_train_dt, y_train_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6862638.663980302, 2619.663845606971, 0.9063014580711598, None, None)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_abr=model_performance(X_train_dt,X_test_dt,y_train_dt,y_test_dt,model_abr)\n",
    "metrics_abr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score on Training data using Ada Boosting Regressor: 0.9352810178228347\n",
      "R2 Score on Test data using Ada Boosting Regressor: 0.9063014580711598\n"
     ]
    }
   ],
   "source": [
    "r2_train_abr=model_abr.score(X_train_dt,y_train_dt)\n",
    "r2_test_abr=metrics_abr[2]\n",
    "print('R2 score on Training data using Ada Boosting Regressor:',r2_train_abr)\n",
    "print('R2 Score on Test data using Ada Boosting Regressor:',r2_test_abr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy:  0.8707922273839696\n",
      "Standard Deviation:  0.07167416812791595\n"
     ]
    }
   ],
   "source": [
    "num_folds = 16\n",
    "seed = 83\n",
    "kfold = KFold(n_splits=num_folds, random_state=seed,shuffle=True)\n",
    "results4 = cross_val_score(model_abr,X_final, y, cv=kfold)\n",
    "accuracy4=np.mean(abs(results4))\n",
    "print('Average accuracy: ',accuracy4)\n",
    "print('Standard Deviation: ',results4.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is once again overfit, with the k fold accuracy of 0.87 and test score of 0.90"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * **Now let us utilise MLR on all the above features before feature engineering and check out the accuracy**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network - MLP Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.36969362\n",
      "Iteration 2, loss = 0.11984851\n",
      "Iteration 3, loss = 0.11189357\n",
      "Iteration 4, loss = 0.07059854\n",
      "Iteration 5, loss = 0.07532732\n",
      "Iteration 6, loss = 0.05548730\n",
      "Iteration 7, loss = 0.05507234\n",
      "Iteration 8, loss = 0.04893984\n",
      "Iteration 9, loss = 0.05085267\n",
      "Iteration 10, loss = 0.04821463\n",
      "Iteration 11, loss = 0.04305642\n",
      "Iteration 12, loss = 0.03700496\n",
      "Iteration 13, loss = 0.03772058\n",
      "Iteration 14, loss = 0.03912835\n",
      "Iteration 15, loss = 0.03415784\n",
      "Iteration 16, loss = 0.03227961\n",
      "Iteration 17, loss = 0.03276144\n",
      "Iteration 18, loss = 0.03419034\n",
      "Iteration 19, loss = 0.02556827\n",
      "Iteration 20, loss = 0.03267300\n",
      "Iteration 21, loss = 0.02775182\n",
      "Iteration 22, loss = 0.02607023\n",
      "Iteration 23, loss = 0.02390569\n",
      "Iteration 24, loss = 0.02265251\n",
      "Iteration 25, loss = 0.02314168\n",
      "Iteration 26, loss = 0.03022357\n",
      "Iteration 27, loss = 0.02387171\n",
      "Iteration 28, loss = 0.02593560\n",
      "Iteration 29, loss = 0.01988948\n",
      "Iteration 30, loss = 0.02203622\n",
      "Iteration 31, loss = 0.01960153\n",
      "Iteration 32, loss = 0.01921137\n",
      "Iteration 33, loss = 0.01585462\n",
      "Iteration 34, loss = 0.01734287\n",
      "Iteration 35, loss = 0.01562951\n",
      "Iteration 36, loss = 0.01584355\n",
      "Iteration 37, loss = 0.01420015\n",
      "Iteration 38, loss = 0.01719602\n",
      "Iteration 39, loss = 0.01461228\n",
      "Iteration 40, loss = 0.01446154\n",
      "Iteration 41, loss = 0.02050443\n",
      "Iteration 42, loss = 0.01544860\n",
      "Iteration 43, loss = 0.01250967\n",
      "Iteration 44, loss = 0.01401887\n",
      "Iteration 45, loss = 0.01187053\n",
      "Iteration 46, loss = 0.01415069\n",
      "Iteration 47, loss = 0.01109774\n",
      "Iteration 48, loss = 0.01107616\n",
      "Iteration 49, loss = 0.01026051\n",
      "Iteration 50, loss = 0.01114450\n",
      "Iteration 51, loss = 0.01061753\n",
      "Iteration 52, loss = 0.00958997\n",
      "Iteration 53, loss = 0.00922327\n",
      "Iteration 54, loss = 0.00916913\n",
      "Iteration 55, loss = 0.00995499\n",
      "Iteration 56, loss = 0.01324401\n",
      "Iteration 57, loss = 0.00919418\n",
      "Iteration 58, loss = 0.01035095\n",
      "Iteration 59, loss = 0.01045381\n",
      "Iteration 60, loss = 0.01028128\n",
      "Iteration 61, loss = 0.01212721\n",
      "Iteration 62, loss = 0.01260720\n",
      "Iteration 63, loss = 0.01065670\n",
      "Iteration 64, loss = 0.00935126\n",
      "Iteration 65, loss = 0.00932809\n",
      "Iteration 66, loss = 0.00842932\n",
      "Iteration 67, loss = 0.00931189\n",
      "Iteration 68, loss = 0.00832698\n",
      "Iteration 69, loss = 0.00832202\n",
      "Iteration 70, loss = 0.00760948\n",
      "Iteration 71, loss = 0.00636231\n",
      "Iteration 72, loss = 0.00697610\n",
      "Iteration 73, loss = 0.00641549\n",
      "Iteration 74, loss = 0.00676856\n",
      "Iteration 75, loss = 0.00627496\n",
      "Iteration 76, loss = 0.00581461\n",
      "Iteration 77, loss = 0.00648467\n",
      "Iteration 78, loss = 0.00657518\n",
      "Iteration 79, loss = 0.00635137\n",
      "Iteration 80, loss = 0.00690149\n",
      "Iteration 81, loss = 0.00608278\n",
      "Iteration 82, loss = 0.00755584\n",
      "Iteration 83, loss = 0.00686528\n",
      "Iteration 84, loss = 0.00658425\n",
      "Iteration 85, loss = 0.00713629\n",
      "Iteration 86, loss = 0.00628429\n",
      "Iteration 87, loss = 0.00683838\n",
      "Iteration 88, loss = 0.00569607\n",
      "Iteration 89, loss = 0.00603289\n",
      "Iteration 90, loss = 0.00584877\n",
      "Iteration 91, loss = 0.00470343\n",
      "Iteration 92, loss = 0.00524028\n",
      "Iteration 93, loss = 0.00573075\n",
      "Iteration 94, loss = 0.00490455\n",
      "Iteration 95, loss = 0.00468764\n",
      "Iteration 96, loss = 0.00539722\n",
      "Iteration 97, loss = 0.00446448\n",
      "Iteration 98, loss = 0.00494069\n",
      "Iteration 99, loss = 0.00460099\n",
      "Iteration 100, loss = 0.00448171\n",
      "Iteration 101, loss = 0.00423473\n",
      "Iteration 102, loss = 0.00454602\n",
      "Iteration 103, loss = 0.00415514\n",
      "Iteration 104, loss = 0.00392747\n",
      "Iteration 105, loss = 0.00404883\n",
      "Iteration 106, loss = 0.00424890\n",
      "Iteration 107, loss = 0.00411046\n",
      "Iteration 108, loss = 0.00500063\n",
      "Iteration 109, loss = 0.00465453\n",
      "Iteration 110, loss = 0.00500913\n",
      "Iteration 111, loss = 0.00455795\n",
      "Iteration 112, loss = 0.00463527\n",
      "Iteration 113, loss = 0.00562941\n",
      "Iteration 114, loss = 0.00435552\n",
      "Iteration 115, loss = 0.00491121\n",
      "Iteration 116, loss = 0.00406771\n",
      "Iteration 117, loss = 0.00496671\n",
      "Iteration 118, loss = 0.00486951\n",
      "Iteration 119, loss = 0.00393473\n",
      "Iteration 120, loss = 0.00431016\n",
      "Iteration 121, loss = 0.00393317\n",
      "Iteration 122, loss = 0.00407465\n",
      "Iteration 123, loss = 0.00407418\n",
      "Iteration 124, loss = 0.00446825\n",
      "Iteration 125, loss = 0.00413522\n",
      "Training loss did not improve more than tol=0.000100 for 20 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-12 {color: black;background-color: white;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPRegressor(batch_size=64, hidden_layer_sizes=(512, 256, 128, 64),\n",
       "             max_iter=1000, n_iter_no_change=20, random_state=2,\n",
       "             validation_fraction=0.2, verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" checked><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(batch_size=64, hidden_layer_sizes=(512, 256, 128, 64),\n",
       "             max_iter=1000, n_iter_no_change=20, random_state=2,\n",
       "             validation_fraction=0.2, verbose=True)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPRegressor(batch_size=64, hidden_layer_sizes=(512, 256, 128, 64),\n",
       "             max_iter=1000, n_iter_no_change=20, random_state=2,\n",
       "             validation_fraction=0.2, verbose=True)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "X=df_z[['length','width','highway_mpg','curb_weight','engine_size','horsepower','city_mpg','wheel_base','bore']]\n",
    "y=df_z['price']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state = 1,shuffle=True)\n",
    "\n",
    "\n",
    "model_mlp =  MLPRegressor(hidden_layer_sizes=(512,256,128,64), max_iter=1000, random_state=2, n_iter_no_change=20 ,validation_fraction=0.2, batch_size=64, verbose=True, activation='relu')\n",
    "model_mlp.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.36969362\n",
      "Iteration 2, loss = 0.11984851\n",
      "Iteration 3, loss = 0.11189357\n",
      "Iteration 4, loss = 0.07059854\n",
      "Iteration 5, loss = 0.07532732\n",
      "Iteration 6, loss = 0.05548730\n",
      "Iteration 7, loss = 0.05507234\n",
      "Iteration 8, loss = 0.04893984\n",
      "Iteration 9, loss = 0.05085267\n",
      "Iteration 10, loss = 0.04821463\n",
      "Iteration 11, loss = 0.04305642\n",
      "Iteration 12, loss = 0.03700496\n",
      "Iteration 13, loss = 0.03772058\n",
      "Iteration 14, loss = 0.03912835\n",
      "Iteration 15, loss = 0.03415784\n",
      "Iteration 16, loss = 0.03227961\n",
      "Iteration 17, loss = 0.03276144\n",
      "Iteration 18, loss = 0.03419034\n",
      "Iteration 19, loss = 0.02556827\n",
      "Iteration 20, loss = 0.03267300\n",
      "Iteration 21, loss = 0.02775182\n",
      "Iteration 22, loss = 0.02607023\n",
      "Iteration 23, loss = 0.02390569\n",
      "Iteration 24, loss = 0.02265251\n",
      "Iteration 25, loss = 0.02314168\n",
      "Iteration 26, loss = 0.03022357\n",
      "Iteration 27, loss = 0.02387171\n",
      "Iteration 28, loss = 0.02593560\n",
      "Iteration 29, loss = 0.01988948\n",
      "Iteration 30, loss = 0.02203622\n",
      "Iteration 31, loss = 0.01960153\n",
      "Iteration 32, loss = 0.01921137\n",
      "Iteration 33, loss = 0.01585462\n",
      "Iteration 34, loss = 0.01734287\n",
      "Iteration 35, loss = 0.01562951\n",
      "Iteration 36, loss = 0.01584355\n",
      "Iteration 37, loss = 0.01420015\n",
      "Iteration 38, loss = 0.01719602\n",
      "Iteration 39, loss = 0.01461228\n",
      "Iteration 40, loss = 0.01446154\n",
      "Iteration 41, loss = 0.02050443\n",
      "Iteration 42, loss = 0.01544860\n",
      "Iteration 43, loss = 0.01250967\n",
      "Iteration 44, loss = 0.01401887\n",
      "Iteration 45, loss = 0.01187053\n",
      "Iteration 46, loss = 0.01415069\n",
      "Iteration 47, loss = 0.01109774\n",
      "Iteration 48, loss = 0.01107616\n",
      "Iteration 49, loss = 0.01026051\n",
      "Iteration 50, loss = 0.01114450\n",
      "Iteration 51, loss = 0.01061753\n",
      "Iteration 52, loss = 0.00958997\n",
      "Iteration 53, loss = 0.00922327\n",
      "Iteration 54, loss = 0.00916913\n",
      "Iteration 55, loss = 0.00995499\n",
      "Iteration 56, loss = 0.01324401\n",
      "Iteration 57, loss = 0.00919418\n",
      "Iteration 58, loss = 0.01035095\n",
      "Iteration 59, loss = 0.01045381\n",
      "Iteration 60, loss = 0.01028128\n",
      "Iteration 61, loss = 0.01212721\n",
      "Iteration 62, loss = 0.01260720\n",
      "Iteration 63, loss = 0.01065670\n",
      "Iteration 64, loss = 0.00935126\n",
      "Iteration 65, loss = 0.00932809\n",
      "Iteration 66, loss = 0.00842932\n",
      "Iteration 67, loss = 0.00931189\n",
      "Iteration 68, loss = 0.00832698\n",
      "Iteration 69, loss = 0.00832202\n",
      "Iteration 70, loss = 0.00760948\n",
      "Iteration 71, loss = 0.00636231\n",
      "Iteration 72, loss = 0.00697610\n",
      "Iteration 73, loss = 0.00641549\n",
      "Iteration 74, loss = 0.00676856\n",
      "Iteration 75, loss = 0.00627496\n",
      "Iteration 76, loss = 0.00581461\n",
      "Iteration 77, loss = 0.00648467\n",
      "Iteration 78, loss = 0.00657518\n",
      "Iteration 79, loss = 0.00635137\n",
      "Iteration 80, loss = 0.00690149\n",
      "Iteration 81, loss = 0.00608278\n",
      "Iteration 82, loss = 0.00755584\n",
      "Iteration 83, loss = 0.00686528\n",
      "Iteration 84, loss = 0.00658425\n",
      "Iteration 85, loss = 0.00713629\n",
      "Iteration 86, loss = 0.00628429\n",
      "Iteration 87, loss = 0.00683838\n",
      "Iteration 88, loss = 0.00569607\n",
      "Iteration 89, loss = 0.00603289\n",
      "Iteration 90, loss = 0.00584877\n",
      "Iteration 91, loss = 0.00470343\n",
      "Iteration 92, loss = 0.00524028\n",
      "Iteration 93, loss = 0.00573075\n",
      "Iteration 94, loss = 0.00490455\n",
      "Iteration 95, loss = 0.00468764\n",
      "Iteration 96, loss = 0.00539722\n",
      "Iteration 97, loss = 0.00446448\n",
      "Iteration 98, loss = 0.00494069\n",
      "Iteration 99, loss = 0.00460099\n",
      "Iteration 100, loss = 0.00448171\n",
      "Iteration 101, loss = 0.00423473\n",
      "Iteration 102, loss = 0.00454602\n",
      "Iteration 103, loss = 0.00415514\n",
      "Iteration 104, loss = 0.00392747\n",
      "Iteration 105, loss = 0.00404883\n",
      "Iteration 106, loss = 0.00424890\n",
      "Iteration 107, loss = 0.00411046\n",
      "Iteration 108, loss = 0.00500063\n",
      "Iteration 109, loss = 0.00465453\n",
      "Iteration 110, loss = 0.00500913\n",
      "Iteration 111, loss = 0.00455795\n",
      "Iteration 112, loss = 0.00463527\n",
      "Iteration 113, loss = 0.00562941\n",
      "Iteration 114, loss = 0.00435552\n",
      "Iteration 115, loss = 0.00491121\n",
      "Iteration 116, loss = 0.00406771\n",
      "Iteration 117, loss = 0.00496671\n",
      "Iteration 118, loss = 0.00486951\n",
      "Iteration 119, loss = 0.00393473\n",
      "Iteration 120, loss = 0.00431016\n",
      "Iteration 121, loss = 0.00393317\n",
      "Iteration 122, loss = 0.00407465\n",
      "Iteration 123, loss = 0.00407418\n",
      "Iteration 124, loss = 0.00446825\n",
      "Iteration 125, loss = 0.00413522\n",
      "Training loss did not improve more than tol=0.000100 for 20 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.09334748011725184, 0.3055281985631635, 0.9195075563343992, None, None)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_mlp=model_performance(X_train, X_test, y_train, y_test,model_mlp)\n",
    "metrics_mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score on Training data using MLR: 0.9920659713101077\n",
      "R2 Score on Test data using MLR: 0.9195075563343992\n"
     ]
    }
   ],
   "source": [
    "r2_train_mlp=model_mlp.score(X_train,y_train)\n",
    "r2_test_mlp=metrics_mlp[2]\n",
    "print('R2 score on Training data using MLR:',r2_train_mlp)\n",
    "print('R2 Score on Test data using MLR:',r2_test_mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From all the above models the best model is Gradient Boosting Regresor , now let us bootstrap sample and verify the confidence internval "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Bootstrap Sampling </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_agg=X.join(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = cars_agg.values\n",
    "\n",
    "n_iterations = 1000\n",
    "\n",
    "n_size = int(len(df_z) * 1)    \n",
    "\n",
    "# run bootstrap\n",
    "# empty list that will hold the scores for each bootstrap iteration\n",
    "stats = list()   \n",
    "for i in range(n_iterations):\n",
    "    \n",
    "    train = resample(values, n_samples=n_size)  # Sampling with replacement \n",
    "    test = np.array([x for x in values if x.tolist() not in train.tolist()])  \n",
    "    \n",
    "    \n",
    "     # fit model\n",
    "    gbr = GradientBoostingRegressor(n_estimators=50)\n",
    "    \n",
    "    gbr.fit(train[:,:-1], train[:,-1]) \n",
    "    \n",
    "\n",
    "    y_test = test[:,-1]    \n",
    "    \n",
    "    score = gbr.score(test[:, :-1] , y_test)\n",
    "    predictions = gbr.predict(test[:, :-1])  \n",
    "\n",
    "    stats.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.0 confidence interval 84.4% and 94.4%\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "pyplot.hist(stats)\n",
    "pyplot.show()\n",
    "# confidence intervals\n",
    "alpha = 0.95                             # for 95% confidence \n",
    "p = ((1.0-alpha)/2.0) * 100              # tail regions on right and left .25 on each side indicated by P value (border)\n",
    "lower = max(0.0, np.percentile(stats, p))  \n",
    "p = (alpha+((1.0-alpha)/2.0)) * 100\n",
    "upper = min(1.0, np.percentile(stats, p))\n",
    "print('%.1f confidence interval %.1f%% and %.1f%%' % (alpha*100, lower*100, upper*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model which I would choose to predict the price of the car is Gradient Boosting regressor with 84.4% to 94.4% confidence interval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Conclusion:</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The features are selected after normalising the data using zscore and important features are choosen using Decsion tree Regressor.\n",
    "* The random forest yields overfit model and the k fold cross validation proves the hypothesis\n",
    "* The gradient boost regressor also results in similar accuracy but the model seems to be good due to similarity in accuracy.\n",
    "* The ADA boost regressor results in less accurate model with likelihood of overfitting\n",
    "* The MLR regressor by choosing all the features gave around 92% with likelihood of model overfit.\n",
    "\n",
    "**From the above results we can conclude the model which is best suited for prediction of car price is Gradient boost Regressor**\n",
    "\n",
    "- After bootstrap sampling the confidence interval of the GRB model yielded around 84.4% to 94.4%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
